{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"smcrZpcKX_X2"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.nn.utils import parameters_to_vector, vector_to_parameters\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1676147827339,"user":{"displayName":"Harshini Reddy","userId":"01996352696643164914"},"user_tz":300},"id":"f_yQuuK2ZSOx","outputId":"0409912b-254b-4bda-eb21-276e9dd73d04"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_dataset size: 60000 \n","test_dataset size: 10000\n"]}],"source":["train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n","                                           \n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n","                                         \n","print(\"train_dataset size:\", len(train_dataset),\"\\ntest_dataset size:\", len(test_dataset))\n","def train_loader(batch_size):\n","  train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=600, shuffle=True) \n","  return train_loader\n","\n","def test_loader(batch_size):                                           \n","  test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n","  return test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GqM8Ew9EaTOR"},"outputs":[],"source":["class M1(nn.Module):\n","  def __init__(self,):\n","        super(M1, self).__init__()\n","        self.fc1 = nn.Linear(784, 500)\n","        self.fc2 = nn.Linear(500, 10)\n","        \n","  def forward(self, x):\n","        # flatten as one dimension\n","        x = x.reshape(x.shape[0], -1)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1676147829497,"user":{"displayName":"Harshini Reddy","userId":"01996352696643164914"},"user_tz":300},"id":"Pr9UvmvOaZqW","outputId":"1d1f862b-6760-4593-eaca-49a10614a31e"},"outputs":[{"data":{"text/plain":["100"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["len(train_loader(6000))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDq7yH6Cab20"},"outputs":[],"source":["def trainFunc(model,num_epochs,train_batch_size,status):\n","    model.train()\n","    print('started')\n","    train_load = train_loader(train_batch_size)\n","    n_total_steps = len(train_load)\n","    train_losses = []\n","    train_epoch = []\n","    train_acc = []\n","    not_converged =True\n","    epoch = 0\n","    trainAvgLossArr = []\n","    trainAvgAccArr = []\n","\n","    while not_converged:\n","        epoch += 1\n","        n_correct = 0\n","        n_samples = 0\n","        lossSum =0\n","        totalacc =0\n","\n","        for i, (images, labels) in enumerate(train_load):  \n","            \n","            images, labels = Variable(images),Variable(labels)\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","            # Forward pass\n","            prediction = model(images)\n","            loss = loss_func(prediction, labels)\n","            lossSum += loss.detach().numpy()\n","            # Backward and optimize\n","            loss.backward()\n","            \n","            optimizer.step()\n","\n","            _, predicted = torch.max(prediction.data, 1)\n","            n_samples += labels.size(0)\n","            n_correct += (predicted == labels).sum().item()\n","            acc = 100.0 * n_correct / n_samples\n","            totalacc += acc\n","            train_losses.append(loss.item())\n","            train_acc.append(acc)\n","            train_epoch.append(epoch)\n","\n","            if (i+1) % status == 0:\n","                print (f'Train O/P: Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}',end= '\\r',flush = True)\n","   \n","                if epoch == num_epochs:\n","                        print(\"Max Epoch Reached\")\n","                        not_converged = False\n","                elif (epoch > 5) and  (train_losses[-1] < 0.001):\n","                    if abs(train_losses[-3] - train_losses[-2]) < 1.0e-05 and abs(train_losses[-2] - train_losses[-1]) < 1.0e-05:\n","                        print(\"Convergeance reached for loss:\",train_losses[-1])\n","                        not_converged = False\n","\n","       \n","        epochAcc = totalacc/(i+1)\n","        trainAvgLossArr.append(lossSum/n_total_steps)    \n","        trainAvgAccArr.append(epochAcc)\n","\n","    return train_epoch,train_losses,train_acc,trainAvgLossArr,trainAvgAccArr\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1676147831575,"user":{"displayName":"Harshini Reddy","userId":"01996352696643164914"},"user_tz":300},"id":"xXYEOvUkbDdX","outputId":"ebb6b52b-bf0d-4403-df10-23b0369ea4fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total no of parameters in Model with batch_size=64 is:397510\n"]}],"source":["torch.manual_seed(1)\n","\n","learning_rate = 0.0015\n","mBatch1 = M1()\n","loss_func = nn.CrossEntropyLoss()\n","weight_decay_val = 1e-4\n","\n","optimizer = torch.optim.Adam(mBatch1.parameters(), lr=learning_rate, weight_decay = weight_decay_val)\n","a=[]\n","for i in mBatch1.parameters():\n","    a.append(torch.numel(i))\n","print(f'Total no of parameters in Model with batch_size={64} is:{np.sum(a)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aeff18D2bHjg","outputId":"e7a0f43d-391d-4b34-ee8a-852aac0090a2"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["started\n"]}],"source":["max_epochs = 2\n","train_batch_size = 64\n","status = 500\n","B1_train_epoch,B1_train_losses,B1_train_acc,B1trainAvgLossArr,B1trainAvgAccArr  = trainFunc(mBatch1,max_epochs,train_batch_size,status)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKudchv1bLrr"},"outputs":[],"source":["torch.manual_seed(1)\n","\n","learning_rate = 0.0015\n","mBatch2 = M1()\n","loss_func = nn.CrossEntropyLoss()\n","weight_decay_val = 1e-4\n","optimizer = torch.optim.Adam(mBatch2.parameters(), lr=learning_rate, weight_decay=weight_decay_val) \n","\n","a=[]\n","for i in mBatch2.parameters():\n","    a.append(torch.numel(i))\n","print(f'Total no of parameters in Model with batch_size={1000} is:{np.sum(a)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"elapsed":201,"status":"error","timestamp":1676147978842,"user":{"displayName":"Harshini Reddy","userId":"01996352696643164914"},"user_tz":300},"id":"Wc4NOXDzbT2V","outputId":"9f4e6624-2bd6-498f-8ef1-08d2a06b0604"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-90a119de13cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mB2_train_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB2_train_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB2_train_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB2trainAvgLossArr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB2trainAvgAccArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmBatch2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'mBatch2' is not defined"]}],"source":["max_epochs = 2\n","train_batch_size = 1000\n","status = 5\n","B2_train_epoch,B2_train_losses,B2_train_acc,B2trainAvgLossArr,B2trainAvgAccArr = trainFunc(mBatch2,max_epochs,train_batch_size,status)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NC057cCSbWWU"},"outputs":[],"source":["epochArr = np.array(np.linspace(1,max_epochs,max_epochs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"di2gmwJPbZG0"},"outputs":[],"source":["plt.figure(figsize=(10, 4))\n","plt.plot(epochArr,B1trainAvgLossArr,color=\"blue\")\n","plt.plot(epochArr,B2trainAvgLossArr,color=\"orange\")\n","plt.title('Batch1 & Bathc2 Loss VS Epoch')\n","plt.legend(['Batch 1','Batch 2'])\n","plt.xlabel ('Epoch')\n","plt.ylabel ('loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDcXjAygbc6m"},"outputs":[],"source":["batch1_param = torch.nn.utils.parameters_to_vector(mBatch1.parameters())\n","print(batch1_param,'\\nlen:',len(batch1_param))\n","\n","batch2_param = torch.nn.utils.parameters_to_vector(mBatch2.parameters())\n","print(batch2_param,'\\nlen:',len(batch2_param))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJi4tsiKbh_V"},"outputs":[],"source":["alpha = np.linspace(-2.0, 2.0, num=31)\n","print(alpha)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJ_oiT-Tbkoz"},"outputs":[],"source":["thetaArr =[]\n","for i in range (len(alpha)):\n","    theta = (1-alpha[i])*batch1_param + alpha[i]*batch2_param\n","    thetaArr.append(theta)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jWwBWA0Gbnif"},"outputs":[],"source":["def testFunction(model,loss_func,testLoader,test_batch_size): \n","    test_loader = testLoader\n","    test_load = test_loader(test_batch_size)\n","    model.eval()\n","    with torch.no_grad():\n","        n_correct = 0\n","        n_samples = 0\n","        testLoss = 0\n","        count =0\n","        for images, labels in test_load:\n","            images, labels = Variable(images),Variable(labels)\n","            \n","            prediction = model(images)\n","            testLoss += loss_func(prediction,labels).item()\n","            # max returns (value ,index)\n","            _, predicted = torch.max(prediction.data, 1)\n","            n_samples += labels.size(0)\n","            n_correct += (predicted == labels).sum().item()\n","            count +=1\n","\n","    netTest_loss = testLoss/count\n","    netTest_acc1 = 100.0 * n_correct / n_samples\n","    print(f'Accuracy of the network on the test images: {netTest_acc1} & Test Loss: {netTest_loss} %', end=\"\\r\", flush= True)\n","    return netTest_acc1, netTest_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4hOrfVlWbqBi"},"outputs":[],"source":["import copy\n","\n","modelsTrainEpochArr = []\n","modelsTrainLossArr = []\n","modelsTrainAccArr = []\n","modelsTestLossArr = []\n","modelsTestAccArr = []\n","\n","for i in range (len(thetaArr)):\n","    \n","    j=copy.deepcopy(i) \n","    theta = (1-alpha[i])*batch1_param + alpha[i]*batch2_param\n","    j = M1()\n","    torch.nn.utils.vector_to_parameters(theta,j.parameters())\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(j.parameters(), lr=0.0004, weight_decay = 1e-4) \n","\n","    a=[]\n","    for k in j.parameters():\n","        a.append(torch.numel(k))\n","    print(f'Total no of parameters in Model Theta {i} is:{np.sum(a)}')\n","\n","    print(j.parameters)\n","\n","    max_epochs = 1\n","    train_batch_size = 500\n","    status = 100\n","    T_train_epoch,T_train_losses,T_train_acc,T_trainAvgLossArr,T_trainAvgAccArr = trainFunc(j,max_epochs,train_batch_size,status)\n","    \n","    \n","    modelsTrainLossArr.append(T_trainAvgLossArr)\n","    modelsTrainAccArr.append(T_trainAvgAccArr)\n","    \n","    test_batch_size=500\n","    T_acc, T_testLoss = testFunction(j,loss_func,test_loader,test_batch_size)\n","    modelsTestAccArr.append(T_acc)\n","    modelsTestLossArr.append(T_testLoss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GafQqtybwD7"},"outputs":[],"source":["def meanScore(dataArr):\n","    meanModelData = []\n","    for i in range (len(dataArr)):\n","        meanScore = np.mean(dataArr[i])\n","        meanModelData.append(meanScore)\n","    return meanModelData\n","\n","def minScore(dataArr):\n","    minModelScore = []\n","    for i in range (len(dataArr)):\n","        minScore = np.mean(dataArr[i])\n","        minModelScore.append(minScore)\n","    return minModelScore\n","\n","def maxScore(dataArr):\n","    maxModelScore = []\n","    for i in range (len(dataArr)):\n","        maxScore = np.max(dataArr[i])\n","        maxModelScore.append(maxScore)\n","    return maxModelScore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WC8GIvddb3Q_"},"outputs":[],"source":["fig,ax=plt.subplots()\n","ax.plot(alpha,(modelsTrainLossArr),color=\"Blue\",linestyle='dashed', marker=\"o\")\n","ax.plot(alpha,modelsTestLossArr,color=\"Blue\", marker=\"v\")\n","ax.legend(['Train Loss','Test Loss'],loc=\"center left\")\n","ax.set_xlabel(\"Alpha\",color=\"Green\")\n","ax.set_ylabel(\"CrossEntropy Loss\",color = \"blue\")\n","\n","\n","ax2=ax.twinx()\n","ax2.plot(alpha,(modelsTrainAccArr),color=\"red\",linestyle='dashed', marker=\"o\")\n","ax2.plot(alpha,modelsTestAccArr,color=\"red\", marker=\"v\")\n","ax2.set_xlabel(\"Alpha\",color=\"Green\")\n","ax2.set_ylabel(\"Accuracy\",color = \"red\")\n","ax2.legend(['Train Acc','Test Acc'],loc=\"upper right\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0POziMeDb6NG"},"outputs":[],"source":["torch.manual_seed(1)\n","\n","learning_rate = 1e-3\n","mLr1 = M1()\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(mLr1.parameters(), lr=learning_rate) \n","\n","a=[]\n","for i in mLr1.parameters():\n","    a.append(torch.numel(i))\n","print(f'Total no of parameters in Model with Lr={learning_rate} is:{np.sum(a)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j529RV7Ab9Ej"},"outputs":[],"source":["max_epochs = 5\n","train_batch_size = 64\n","status = 10\n","L1_train_epoch,L1_train_losses,L1_train_acc,L1_trainAvgLossArr,L1_trainAvgAccArr  = trainFunc(mLr1,max_epochs,train_batch_size,status)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZYYmDt3cARO"},"outputs":[],"source":["Lr1_param = torch.nn.utils.parameters_to_vector(mLr1.parameters())\n","print(Lr1_param,'\\nlen:',len(Lr1_param))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMKaFc_6cC0Z"},"outputs":[],"source":["torch.manual_seed(1)\n","learning_rate = 1e-2\n","mLr2 = M1()\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(mLr2.parameters(), lr=learning_rate) \n","\n","a=[]\n","for i in mLr2.parameters():\n","    a.append(torch.numel(i))\n","print(f'Total no of parameters in Model with Lr={learning_rate} is:{np.sum(a)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zi3ydgiQcGxq"},"outputs":[],"source":["max_epochs = 5\n","train_batch_size = 64\n","status = 10\n","L2_train_epoch,L2_train_losses,L2_train_acc,L2_trainAvgLossArr,L2_trainAvgAccArr  = trainFunc(mLr2,max_epochs,train_batch_size,status)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gLb_bUEcKRn"},"outputs":[],"source":["epochArr = np.array(np.linspace(1,max_epochs,max_epochs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PT_cLQ96cMnW"},"outputs":[],"source":["plt.figure(figsize=(10, 4))\n","plt.plot(epochArr,L1_trainAvgLossArr,color=\"blue\")\n","plt.plot(epochArr,L2_trainAvgLossArr,color=\"orange\")\n","plt.title('Lr1 & Lr2 Loss VS Epoch',color=\"green\")\n","plt.legend(['LR1:1e-3 1','LR2:1e-2'])\n","plt.xlabel ('Epoch')\n","plt.ylabel ('loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_Y75wyScO67"},"outputs":[],"source":["Lr2_param = torch.nn.utils.parameters_to_vector(mLr2.parameters())\n","print(Lr2_param,'\\nlen:',len(Lr2_param))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wdzDscQcTNA"},"outputs":[],"source":["modelsTrainEpochArr2 = []\n","modelsTrainLossArr2 = []\n","modelsTrainAccArr2 = []\n","modelsTestLossArr2 = []\n","modelsTestAccArr2 = []\n","\n","for i in range (len(thetaArr)):\n","    torch.manual_seed(1)\n","    j=copy.deepcopy(i) \n","    theta = (1-alpha[i])*Lr1_param + alpha[i]*Lr2_param\n","    j = M1()\n","    torch.nn.utils.vector_to_parameters(theta,j.parameters())\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(j.parameters(), lr=1e-3) #,weight_decay = 0.025)\n","\n","    a=[]\n","    for k in j.parameters():\n","        a.append(torch.numel(k))\n","    print(f'Total no of parameters in Model Theta {i} is:{np.sum(a)}')\n","\n","    print(j.parameters)\n","\n","    max_epochs = 1\n","    train_batch_size = 1000\n","    status = 60\n","    T2_train_epoch,T2_train_losses,T2_train_acc,T2_trainAvgLossArr,T2_trainAvgAccArr = trainFunc(j,max_epochs,train_batch_size,status) #trainFunc(mBatch1,max_epochs,train_batch_size)\n","    \n","    \n","    #modelsTrainEpochArr2.append(T2_trainAvgLossArr)\n","    modelsTrainLossArr2.append(T2_trainAvgLossArr)\n","    modelsTrainAccArr2.append(T2_trainAvgAccArr)\n","    \n","    test_batch_size=1000\n","    T2_acc,T2_testLoss = testFunction(j,loss_func,test_loader,test_batch_size)\n","    modelsTestAccArr2.append(T2_acc)\n","    modelsTestLossArr2.append(T2_testLoss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlsaEw-KcX5T"},"outputs":[],"source":["fig,ax=plt.subplots()\n","ax.plot(alpha,(modelsTrainLossArr2),color=\"Blue\",linestyle='dashed', marker=\"o\")\n","ax.plot(alpha,modelsTestLossArr2,color=\"Blue\", marker=\"v\")\n","ax.legend(['Train Loss','Test Loss'],loc=\"center left\")\n","ax.set_xlabel(\"Alpha\",color=\"Green\")\n","ax.set_ylabel(\"CrossEntropy Loss\",color = \"blue\")\n","ax.set_title(\"learning rate 1e-3 vs. 1e-2\",color = \"green\")\n","\n","\n","ax2=ax.twinx()\n","ax2.plot(alpha,(modelsTrainAccArr2),color=\"red\",linestyle='dashed', marker=\"o\")\n","ax2.plot(alpha,modelsTestAccArr2,color=\"red\", marker=\"v\")\n","ax2.set_xlabel(\"Alpha\",color=\"Green\")\n","ax2.set_ylabel(\"Accuracy\",color = \"red\")\n","ax2.legend(['Train Acc','Test Acc'],loc=\"upper right\")\n","plt.show()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbgnkTZDoobDbls+5rvLKc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}